{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Saving words from newspaper titles in textfiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Titles extracted and written to 'titles.txt'.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Path to the JSON file\n",
    "json_file_path = 'cdx_results_2019.json'\n",
    "\n",
    "# Open and load the JSON file\n",
    "with open(json_file_path, 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# List to store the URLs\n",
    "urls = []\n",
    "\n",
    "# Loop through the data and extract 'url' values\n",
    "for entry in data:\n",
    "    if 'url' in entry:  # Check if 'url' key exists\n",
    "        urls.append(entry['url'])  # Add the URL to the list\n",
    "\n",
    "# Open a file to write the results\n",
    "with open(\"titles.txt\", \"w\") as file:\n",
    "    # Loop through each URL\n",
    "    for url in urls:\n",
    "        # Remove 'https://' and split the URL at slashes\n",
    "        parts = url.split('/')\n",
    "        \n",
    "        # Extract the last part after the slash, which usually contains the title\n",
    "        title_with_params = parts[-1]\n",
    "        \n",
    "        # Remove any parameters (everything after '?')\n",
    "        title = title_with_params.split('?')[0]\n",
    "        \n",
    "        # Replace hyphens with spaces to improve readability\n",
    "        formatted_title = title.replace('-', ' ')\n",
    "        \n",
    "        # Write the formatted title to the file\n",
    "        file.write(f\"{formatted_title}\\n\")\n",
    "\n",
    "print(\"Titles extracted and written to 'titles.txt'.\")\n",
    "\n",
    "# maybe store urls and words wich belong togethers in a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Function to split the URL into words from the title\n",
    "def split_url_in_words(url):\n",
    "    # Remove 'https://' and split the URL at slashes\n",
    "    parts = url.split('/')\n",
    "    \n",
    "    # Extract the last part after the slash, which usually contains the title\n",
    "    title_with_params = parts[-1]\n",
    "    \n",
    "    # Remove any parameters (everything after '?')\n",
    "    title = title_with_params.split('?')[0]\n",
    "    \n",
    "    # Replace hyphens with spaces to improve readability\n",
    "    formatted_title = title.replace('-', ' ')\n",
    "    \n",
    "    # Return the split words\n",
    "    return formatted_title\n",
    "\n",
    "# Path to the JSON file\n",
    "json_file_path = 'cdx_results_2019.json'\n",
    "\n",
    "# Open and load the JSON file\n",
    "with open(json_file_path, 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Empty dictionary to store the URLs as keys and the split title words as values\n",
    "urls = {}\n",
    "\n",
    "# Iterate through the JSON data\n",
    "for entry in data:\n",
    "    if 'url' in entry:\n",
    "        #url = entry['url']  # Get the full URL\n",
    "        #split_title = split_url_in_words(url)  # Split the URL title into words\n",
    "        #urls[str(entry['url'])] = split_title  # Store the URL as key and split title as value\n",
    "        urls[str(entry['url'])] = split_url_in_words(entry['url'])\n",
    "\n",
    "# Writing dictionary to a textfile\n",
    "with open('urls_titles.json', 'w') as output_file:\n",
    "    json.dump(urls, output_file, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Trying to scrape only the <head> elements in the links and look up in the headline if Chega is written as: 'Chega' or 'CHEGA':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Path to the JSON file\n",
    "json_file_path = 'test_for_scraping_cdx_results.json'\n",
    "\n",
    "# Open and load the JSON file\n",
    "with open(json_file_path, 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "titles = {}\n",
    "\n",
    "# Observation: in cmjornal, jn.pt and eco.sapo.pt there is the heading in the title element. so dont search for h-elements, only for title\n",
    "# Loop through URLs; scrape every head-container and search for the head element\n",
    "for v in data:\n",
    "    # Requesting the website and getting html-content\n",
    "    response = requests.get(v['url'], timeout=50, stream=True)\n",
    "    html_content = b\"\"\n",
    "    for chunk in response.iter_content(chunk_size=512):\n",
    "        html_content += chunk\n",
    "    if b\"</title>\" in html_content:  # Stop when </title> is found\n",
    "        break\n",
    "\n",
    "    html_content = response.content\n",
    "\n",
    "    # HTML parsing with BeautifulSoup\n",
    "    soup = BeautifulSoup(html_content, \"lxml\")\n",
    "\n",
    "    # all title containers are extracted from title\n",
    "    title_tag = soup.find(\"title\")\n",
    "\n",
    "    # splitting content out of full tag string\n",
    "\n",
    "    title_content = title_tag.get_text()\n",
    "\n",
    "    # check, if title contains chega; checking at 'Chega' and 'CHEGA', because 'chega' like in title has different meaning and matches more often \n",
    "    if \"Chega\" in title_content or \"CHEGA\" in title_content:\n",
    "        url = v['url']\n",
    "        titles[url] = title_content\n",
    "\n",
    "with open('valid_url_values.txt', 'w') as convert_file: \n",
    "     convert_file.write(json.dumps(titles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.cmjornal.pt/politica/amp/andre-ventura-diz-chega-vai-impedir-extrema-direita-em-portugal: André Ventura diz que Chega vai impedir extrema-direita em Portugal - Política - Correio da Manhã\n",
      "https://www.cmjornal.pt/politica/amp/partido-chega-de-andre-ventura-inicia-formalizacao-para-ser-alternativa-a-direita-que-parece-nao-existir: Partido 'CHEGA' inicia formalização para ser alternativa \"à direita que parece não existir\"  - Política - Correio da Manhã\n"
     ]
    }
   ],
   "source": [
    "# Debug output:\n",
    "\n",
    "for url, title in titles.items():\n",
    "    print(f'{url}: {title}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
