{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial analysis of the collected data (number of counts, period for the timestamps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "import spacy\n",
    "from spacy.tokens import Doc\n",
    "#spacy.cli.download(\"pt_core_news_sm\")\n",
    "from spacy.lang.pt.examples import sentences \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('pt_core_news_sm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count the number of occurrences of each entry and remove the duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>status</th>\n",
       "      <th>url count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13877</th>\n",
       "      <td>https://www.sapo.pt/prime/article/fc-porto-che...</td>\n",
       "      <td>1970-08-22 16:33:44.171433</td>\n",
       "      <td>200</td>\n",
       "      <td>127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13878</th>\n",
       "      <td>https://www.sapo.pt/prime/article/fc-porto-che...</td>\n",
       "      <td>1970-08-22 16:33:44.175956</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13895</th>\n",
       "      <td>http://www.sapo.pt/prime/article/fc-porto-cheg...</td>\n",
       "      <td>1970-08-22 16:35:02.011304</td>\n",
       "      <td>200</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13896</th>\n",
       "      <td>http://www.sapo.pt/prime/article/fc-porto-cheg...</td>\n",
       "      <td>1970-08-22 16:35:02.011308</td>\n",
       "      <td>200</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13898</th>\n",
       "      <td>http://www.sapo.pt/prime/article/fc-porto-cheg...</td>\n",
       "      <td>1970-08-22 16:35:02.021135</td>\n",
       "      <td>200</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     url  \\\n",
       "13877  https://www.sapo.pt/prime/article/fc-porto-che...   \n",
       "13878  https://www.sapo.pt/prime/article/fc-porto-che...   \n",
       "13895  http://www.sapo.pt/prime/article/fc-porto-cheg...   \n",
       "13896  http://www.sapo.pt/prime/article/fc-porto-cheg...   \n",
       "13898  http://www.sapo.pt/prime/article/fc-porto-cheg...   \n",
       "\n",
       "                       timestamp  status  url count  \n",
       "13877 1970-08-22 16:33:44.171433     200        127  \n",
       "13878 1970-08-22 16:33:44.175956     200          1  \n",
       "13895 1970-08-22 16:35:02.011304     200          2  \n",
       "13896 1970-08-22 16:35:02.011308     200          2  \n",
       "13898 1970-08-22 16:35:02.021135     200          2  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a DataFrame to store the data analysed\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    \"Newspaper\": [],\n",
    "    \"Number of occurences\": [],\n",
    "    \"Period\": []\n",
    "    })\n",
    "\n",
    "\n",
    "# Newspapers to search\n",
    "\n",
    "newsp = ['cmjornal.pt/', \n",
    "         'dn.pt/',\n",
    "         'expresso.pt/',\n",
    "         'folhanacional.pt/',\n",
    "         'jn.pt/',\n",
    "         'ionline.sapo.pt/',   \n",
    "         'sol.sapo.pt/',\n",
    "         'observador.pt/',\n",
    "         'publico.pt/',\n",
    "         'sabado.pt/',\n",
    "         'sapo.pt/',\n",
    "         'visao.pt/',\n",
    "         ]\n",
    "\n",
    "# Years of the analysis\n",
    "\n",
    "years = ['2019', '2020-2021', '2022-2024']\n",
    "\n",
    "# Counting the number of occurrences for each of the newspapers in the defined periods\n",
    "\n",
    "for y in years:\n",
    "    with open(\"/Users/joaop.cardoso/MestradoCD/FCD/FDS_Project/cdx_results_json_files/cdx_results_\"+y+\".json\", \"r\") as f:\n",
    "        data = f.read()\n",
    "        for i in newsp:\n",
    "                total = data.count(i)\n",
    "                df.loc[len(df)] = [i, total, y]\n",
    "\n",
    "# Count the number of occurrences of each item in the URL column and save it to the dataframe w/o the timestamp\n",
    "\n",
    "yearly_data = {}\n",
    "yearly_data_no_dupl = {}\n",
    "df_no_dupl = {}\n",
    "\n",
    "for y in years:\n",
    "    # Read the dataframe, count the number of URLs, merge the count to origina DF and then remove all duplicates based on URL\n",
    "    df = pd.read_json(\"/Users/joaop.cardoso/MestradoCD/FCD/FDS_Project/cdx_results_json_files/cdx_results_\"+y+\".json\")\n",
    "\n",
    "    # Count the repeated urls in each of the .json files\n",
    "    url_count = df.groupby(df['url']).size().reset_index(name = 'url count')\n",
    "\n",
    "    # Merge the column (list) of counted values per url into the original DF\n",
    "    yearly_data[f\"df_{y}\"] = df.merge(url_count, on = 'url', how = 'left')\n",
    "    \n",
    "    # Add the dataframes into a new dictionary\n",
    "    yearly_data_no_dupl[f\"df_{y}\"] = yearly_data[f\"df_{y}\"].drop_duplicates(subset = ['url'], keep = 'first')\n",
    "\n",
    "yearly_data_no_dupl['df_2019'].tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separate the title from the rest of the URL to enable text analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['https:', '', 'www.cmjornal.pt', 'famosos', 'amp', 'irma-de-luciana-abreu-chega-de-fazer-sofrer-a-nossa-mae']\n",
      "['irma', 'de', 'luciana', 'abreu', 'chega', 'de', 'fazer', 'sofrer', 'a', 'nossa']\n",
      "Word: irma, POS: VERB, Detailed Tag: VERB\n",
      "Word: de, POS: ADP, Detailed Tag: ADP\n",
      "Word: luciana, POS: NOUN, Detailed Tag: NOUN\n",
      "Word: abreu, POS: VERB, Detailed Tag: VERB\n",
      "Word: chega, POS: NOUN, Detailed Tag: NOUN\n",
      "Word: de, POS: SCONJ, Detailed Tag: SCONJ\n",
      "Word: fazer, POS: VERB, Detailed Tag: VERB\n",
      "Word: sofrer, POS: VERB, Detailed Tag: VERB\n",
      "Word: a, POS: DET, Detailed Tag: DET\n",
      "Word: nossa, POS: DET, Detailed Tag: DET\n",
      "Word: O, POS: DET, Detailed Tag: DET\n",
      "Word: presidente, POS: NOUN, Detailed Tag: NOUN\n",
      "Word: chega, POS: VERB, Detailed Tag: VERB\n",
      "Word: ao, POS: ADP, Detailed Tag: ADP\n",
      "Word: local, POS: NOUN, Detailed Tag: NOUN\n",
      "Word: ., POS: PUNCT, Detailed Tag: PUNCT\n"
     ]
    }
   ],
   "source": [
    "# Testing the methods for splitting text w/in URL, and analyzing the word 'chega'\n",
    "\n",
    "x = \"http://www.sapo.pt/prime/article/fc-porto-chega-ao-classico-na-luz-ensombrado-_5d60e7d99474b37d1ce81d86//\"\n",
    "\n",
    "x1 = \"https://www.cmjornal.pt/famosos/amp/irma-de-luciana-abreu-chega-de-fazer-sofrer-a-nossa-mae\"\n",
    "\n",
    "x2 = \"O presidente chega ao local.\"\n",
    "\n",
    "doc = nlp(x2)\n",
    "\n",
    "y_sent = []\n",
    "\n",
    "# The method rsplit splits the url string taking \"-\" as the delimiter. [1:-1] removes the first and last instance\n",
    "\n",
    "last_part = x1.rsplit('/')\n",
    "print(last_part)\n",
    "\n",
    "for i in last_part:\n",
    "    if \"-\" in i:\n",
    "        y = i.rsplit('-')[0:-1]\n",
    "        print(y)\n",
    "        y_sent = nlp(\" \".join(y))\n",
    "\n",
    "for token in nlp.get_pipe(\"morphologizer\")(y_sent):\n",
    "    print(f\"Word: {token.text}, POS: {token.pos_}, Detailed Tag: {token.tag_}\")\n",
    "\n",
    "for token in nlp.get_pipe(\"morphologizer\")(doc):\n",
    "    print(f\"Word: {token.text}, POS: {token.pos_}, Detailed Tag: {token.tag_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to process the title\n",
    "def title_input(df, year): \n",
    "    processed_texts = []  # Initialize inside the function\n",
    "\n",
    "    # Extract the last part of each URL and process it with SpaCy\n",
    "    last_part = df['url'].str.rsplit('/').str[-1]\n",
    "    for part in last_part:\n",
    "        if \"-\" in part:\n",
    "            parts = part.rsplit('-')[0:-1]  # Split by '-' and remove the last element\n",
    "            sentence = \" \".join(parts)  # Join parts to form a sentence\n",
    "            processed_sentence = nlp(sentence)  # Process with SpaCy\n",
    "            processed_texts.append(\" \".join(token.text for token in processed_sentence))\n",
    "        else:\n",
    "            processed_texts.append(\"\")  # Append an empty string if no processing was done\n",
    "\n",
    "    # Use .loc to avoid SettingWithCopyWarning\n",
    "    df = df.copy()  # Create a copy to avoid SettingWithCopyWarning if df is a slice\n",
    "    df.loc[:, 'processed_url_text'] = processed_texts\n",
    "    \n",
    "    # Drop duplicates based on the 'processed_url_text' column within the df DataFrame\n",
    "    df = df.drop_duplicates(subset=['processed_url_text'], keep='first').reset_index(drop=True)\n",
    "    \n",
    "    # Update the original DataFrame dictionary with the filtered DataFrame\n",
    "    yearly_data_no_dupl[f\"df_{year}\"] = df\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to filter the dataframe, for links with \"chega\" and \"andre ventura\"\n",
    "def filter_dataframe(df, text_column=\"processed_url_text\"):\n",
    "    # List to keep track of row indices that meet the criteria\n",
    "    indices_to_keep = []\n",
    "\n",
    "    # Iterate over each row in the DataFrame to access both the index and text\n",
    "    for index, row in df.iterrows():\n",
    "        text = row[text_column]\n",
    "        \n",
    "        # Skip if the text is NaN\n",
    "        if pd.isna(text):\n",
    "            continue\n",
    "        \n",
    "        doc = nlp(text)\n",
    "\n",
    "        # Check if \"chega\" appears as a noun in the document\n",
    "        is_chega_noun = any(token.text.lower() == \"chega\" and token.pos_ == \"NOUN\" for token in doc)\n",
    "\n",
    "        # Check if both \"andre\" and \"ventura\" appear in the document\n",
    "        contains_andre_ventura = \"andre\" in text.lower() and \"ventura\" in text.lower()\n",
    "\n",
    "        # If either condition is met, keep the row index\n",
    "        if is_chega_noun or contains_andre_ventura:\n",
    "            indices_to_keep.append(index)\n",
    "\n",
    "    # Filter the DataFrame to only include rows that meet the criteria\n",
    "    df = df.loc[indices_to_keep].reset_index(drop=True)\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary to store the filtered dataframes\n",
    "\n",
    "filtered_dfs = {}\n",
    "# Apply the title_input and filter_dataframe functions\n",
    "for y in years:\n",
    "    yearly_data_no_dupl[f\"df_{y}\"] = title_input(yearly_data_no_dupl[f\"df_{y}\"], y)\n",
    "    filtered_dfs[f\"filtered_df_{y}\"] = filter_dataframe(yearly_data_no_dupl[f\"df_{y}\"])\n",
    "    filtered_dfs[f\"filtered_df_{y}\"] = filtered_dfs[f\"filtered_df_{y}\"].rename(columns={\"processed_url_text\": \"title\"})\n",
    "\n",
    "print(filtered_dfs['filtered_df_2019'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>status</th>\n",
       "      <th>url count</th>\n",
       "      <th>title</th>\n",
       "      <th>newspaper</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.cmjornal.pt/famosos/amp/irma-de-lu...</td>\n",
       "      <td>1970-08-22 16:23:46.194334</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>irma de luciana abreu chega de fazer sofrer a ...</td>\n",
       "      <td>cmjornal.pt/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.cmjornal.pt/famosos/detalhe/irma-d...</td>\n",
       "      <td>1970-08-22 16:23:46.204109</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>irma de luciana abreu chega de fazer sofrer a ...</td>\n",
       "      <td>cmjornal.pt/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.cmjornal.pt/opiniao/colunistas/edu...</td>\n",
       "      <td>1970-08-22 16:36:58.180706</td>\n",
       "      <td>200</td>\n",
       "      <td>2</td>\n",
       "      <td>rap promotor do chega de</td>\n",
       "      <td>cmjornal.pt/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.cmjornal.pt/politica/amp/andre-ven...</td>\n",
       "      <td>1970-08-22 16:37:08.191131</td>\n",
       "      <td>200</td>\n",
       "      <td>6</td>\n",
       "      <td>andre ventura diz chega vai impedir extrema di...</td>\n",
       "      <td>cmjornal.pt/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.cmjornal.pt/politica/amp/andre-ven...</td>\n",
       "      <td>1970-08-22 16:37:06.194953</td>\n",
       "      <td>200</td>\n",
       "      <td>2</td>\n",
       "      <td>andre ventura do chega nao vai a posse do gove...</td>\n",
       "      <td>cmjornal.pt/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>https://ionline.sapo.pt/artigo/679333/projeto-...</td>\n",
       "      <td>1970-08-22 16:40:07.181559</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>projeto de castracao quimica do chega ja foi e...</td>\n",
       "      <td>ionline.sapo.pt/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>https://www.sapo.pt/noticias/amp/nacional/depu...</td>\n",
       "      <td>1970-08-22 16:38:41.195155</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>deputado do chega e recebido com aplausos</td>\n",
       "      <td>sapo.pt/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>https://www.sapo.pt/noticias/motores/skoda-kos...</td>\n",
       "      <td>1970-08-22 16:22:04.183553</td>\n",
       "      <td>200</td>\n",
       "      <td>3</td>\n",
       "      <td>skoda kosmiq o suv urbano da skoda chega</td>\n",
       "      <td>sapo.pt/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>https://www.sapo.pt/noticias/nacional/listas-d...</td>\n",
       "      <td>1970-08-22 16:33:25.172133</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>listas do chega vao integrar elementos</td>\n",
       "      <td>sapo.pt/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>https://www.sapo.pt/noticias/nacional/ventura-...</td>\n",
       "      <td>1970-08-22 16:30:30.172924</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>ventura cabeca de lista do chega em lisboa e</td>\n",
       "      <td>sapo.pt/</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>88 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  url  \\\n",
       "0   https://www.cmjornal.pt/famosos/amp/irma-de-lu...   \n",
       "1   https://www.cmjornal.pt/famosos/detalhe/irma-d...   \n",
       "2   https://www.cmjornal.pt/opiniao/colunistas/edu...   \n",
       "3   https://www.cmjornal.pt/politica/amp/andre-ven...   \n",
       "4   https://www.cmjornal.pt/politica/amp/andre-ven...   \n",
       "..                                                ...   \n",
       "83  https://ionline.sapo.pt/artigo/679333/projeto-...   \n",
       "84  https://www.sapo.pt/noticias/amp/nacional/depu...   \n",
       "85  https://www.sapo.pt/noticias/motores/skoda-kos...   \n",
       "86  https://www.sapo.pt/noticias/nacional/listas-d...   \n",
       "87  https://www.sapo.pt/noticias/nacional/ventura-...   \n",
       "\n",
       "                    timestamp  status  url count  \\\n",
       "0  1970-08-22 16:23:46.194334     200          1   \n",
       "1  1970-08-22 16:23:46.204109     200          1   \n",
       "2  1970-08-22 16:36:58.180706     200          2   \n",
       "3  1970-08-22 16:37:08.191131     200          6   \n",
       "4  1970-08-22 16:37:06.194953     200          2   \n",
       "..                        ...     ...        ...   \n",
       "83 1970-08-22 16:40:07.181559     200          1   \n",
       "84 1970-08-22 16:38:41.195155     200          1   \n",
       "85 1970-08-22 16:22:04.183553     200          3   \n",
       "86 1970-08-22 16:33:25.172133     200          1   \n",
       "87 1970-08-22 16:30:30.172924     200          1   \n",
       "\n",
       "                                                title         newspaper  \n",
       "0   irma de luciana abreu chega de fazer sofrer a ...      cmjornal.pt/  \n",
       "1   irma de luciana abreu chega de fazer sofrer a ...      cmjornal.pt/  \n",
       "2                            rap promotor do chega de      cmjornal.pt/  \n",
       "3   andre ventura diz chega vai impedir extrema di...      cmjornal.pt/  \n",
       "4   andre ventura do chega nao vai a posse do gove...      cmjornal.pt/  \n",
       "..                                                ...               ...  \n",
       "83  projeto de castracao quimica do chega ja foi e...  ionline.sapo.pt/  \n",
       "84          deputado do chega e recebido com aplausos          sapo.pt/  \n",
       "85           skoda kosmiq o suv urbano da skoda chega          sapo.pt/  \n",
       "86             listas do chega vao integrar elementos          sapo.pt/  \n",
       "87       ventura cabeca de lista do chega em lisboa e          sapo.pt/  \n",
       "\n",
       "[88 rows x 6 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function to find the newspaper name in the URL\n",
    "def find_newspaper(url):\n",
    "    for newspaper in newsp:\n",
    "        if newspaper in url:\n",
    "            return newspaper\n",
    "    return None  # Return None if no newspaper is found\n",
    "\n",
    "# Create the 'newspaper' column\n",
    "for y in years:\n",
    "    filtered_dfs[f\"filtered_df_{y}\"]['newspaper'] = filtered_dfs[f\"filtered_df_{y}\"]['url'].apply(find_newspaper)\n",
    "\n",
    "filtered_dfs['filtered_df_2019']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "masters",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
